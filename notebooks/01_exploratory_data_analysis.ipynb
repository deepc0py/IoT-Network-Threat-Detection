{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IoT Network Threat Detection - Exploratory Data Analysis\n",
    "\n",
    "**Project:** IoT Network Threat Detection using Machine Learning  \n",
    "**Dataset:** TON_IoT from UNSW Canberra Cyber  \n",
    "**Date:** July 18, 2025  \n",
    "**Phase:** 1 - Data Processing and Environment Setup\n",
    "\n",
    "## Objectives\n",
    "1. Understand the structure and characteristics of TON_IoT datasets\n",
    "2. Identify key features for threat detection\n",
    "3. Analyze class distributions and imbalance\n",
    "4. Prepare data preprocessing strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Data paths\n",
    "DATA_DIR = Path('../data')\n",
    "IOT_DIR = DATA_DIR / 'Processed_IoT_dataset'\n",
    "NETWORK_DIR = DATA_DIR / 'Processed_Network_dataset'\n",
    "GROUND_TRUTH_DIR = DATA_DIR / 'SecuityEvents_GroundTruth_datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IoT Device Data Analysis\n",
    "\n",
    "Let's start by examining the IoT device datasets. These represent network traffic from various IoT devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IoT Thermostat dataset as our primary example\n",
    "df_thermostat = pd.read_csv(IOT_DIR / 'IoT_Thermostat.csv')\n",
    "\n",
    "print(\"=== IoT THERMOSTAT DATASET OVERVIEW ===\")\n",
    "print(f\"Shape: {df_thermostat.shape}\")\n",
    "print(f\"Memory usage: {df_thermostat.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"\\nColumns: {df_thermostat.columns.tolist()}\")\n",
    "print(f\"\\nData types:\\n{df_thermostat.dtypes}\")\n",
    "print(f\"\\nNull values:\\n{df_thermostat.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution analysis\n",
    "print(\"=== CLASS DISTRIBUTION ===\")\n",
    "print(\"\\nBinary labels:\")\n",
    "print(df_thermostat['label'].value_counts())\n",
    "print(f\"\\nClass imbalance ratio: {df_thermostat['label'].value_counts()[0] / df_thermostat['label'].value_counts()[1]:.2f}:1\")\n",
    "\n",
    "print(\"\\nAttack types:\")\n",
    "print(df_thermostat['type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Binary classification\n",
    "df_thermostat['label'].value_counts().plot(kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Binary Classification\\n(0=Normal, 1=Attack)')\n",
    "axes[0].set_xlabel('Class')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Multi-class classification\n",
    "df_thermostat['type'].value_counts().plot(kind='bar', ax=axes[1])\n",
    "axes[1].set_title('Multi-class Classification\\n(Attack Types)')\n",
    "axes[1].set_xlabel('Attack Type')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature analysis\n",
    "print(\"=== FEATURE ANALYSIS ===\")\n",
    "print(\"\\nStatistical summary:\")\n",
    "print(df_thermostat.describe())\n",
    "\n",
    "print(\"\\nUnique values per feature:\")\n",
    "for col in df_thermostat.columns:\n",
    "    print(f\"{col}: {df_thermostat[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature and status analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Temperature distribution by class\n",
    "normal_data = df_thermostat[df_thermostat['label'] == 0]['current_temperature']\n",
    "attack_data = df_thermostat[df_thermostat['label'] == 1]['current_temperature']\n",
    "\n",
    "axes[0].hist(normal_data, bins=50, alpha=0.7, label='Normal', density=True)\n",
    "axes[0].hist(attack_data, bins=50, alpha=0.7, label='Attack', density=True)\n",
    "axes[0].set_xlabel('Temperature')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].set_title('Temperature Distribution by Class')\n",
    "axes[0].legend()\n",
    "\n",
    "# Thermostat status distribution\n",
    "status_counts = df_thermostat.groupby(['thermostat_status', 'label']).size().unstack(fill_value=0)\n",
    "status_counts.plot(kind='bar', ax=axes[1])\n",
    "axes[1].set_title('Thermostat Status vs Attack Labels')\n",
    "axes[1].set_xlabel('Thermostat Status')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].legend(['Normal', 'Attack'])\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Network Traffic Data Analysis\n",
    "\n",
    "Now let's examine the network traffic datasets, which contain more detailed network-level features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Network dataset (sample one file)\n",
    "df_network = pd.read_csv(NETWORK_DIR / 'Network_dataset_1.csv', low_memory=False)\n",
    "\n",
    "print(\"=== NETWORK DATASET OVERVIEW ===\")\n",
    "print(f\"Shape: {df_network.shape}\")\n",
    "print(f\"Memory usage: {df_network.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"\\nColumns ({len(df_network.columns)}):\")\n",
    "print(df_network.columns.tolist())\n",
    "print(f\"\\nData types:\\n{df_network.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network dataset class distribution\n",
    "print(\"=== NETWORK DATASET CLASS DISTRIBUTION ===\")\n",
    "print(\"\\nBinary labels:\")\n",
    "print(df_network['label'].value_counts())\n",
    "print(f\"\\nClass imbalance ratio: {df_network['label'].value_counts()[1] / df_network['label'].value_counts()[0]:.2f}:1\")\n",
    "\n",
    "if 'type' in df_network.columns:\n",
    "    print(\"\\nAttack types:\")\n",
    "    print(df_network['type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key network features analysis\n",
    "print(\"=== KEY NETWORK FEATURES ===\")\n",
    "key_features = ['duration', 'src_bytes', 'dst_bytes', 'src_pkts', 'dst_pkts']\n",
    "available_features = [f for f in key_features if f in df_network.columns]\n",
    "\n",
    "print(f\"\\nAnalyzing features: {available_features}\")\n",
    "print(df_network[available_features].describe())\n",
    "\n",
    "# Null values in key features\n",
    "print(\"\\nNull values in key features:\")\n",
    "print(df_network[available_features].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protocol and service analysis\n",
    "print(\"=== PROTOCOL AND SERVICE ANALYSIS ===\")\n",
    "if 'proto' in df_network.columns:\n",
    "    print(\"\\nProtocol distribution:\")\n",
    "    print(df_network['proto'].value_counts().head(10))\n",
    "\n",
    "if 'service' in df_network.columns:\n",
    "    print(\"\\nService distribution:\")\n",
    "    print(df_network['service'].value_counts().head(10))\n",
    "\n",
    "if 'conn_state' in df_network.columns:\n",
    "    print(\"\\nConnection state distribution:\")\n",
    "    print(df_network['conn_state'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment\n",
    "\n",
    "Let's assess the overall data quality and identify preprocessing requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality assessment\n",
    "def assess_data_quality(df, dataset_name):\n",
    "    print(f\"=== DATA QUALITY ASSESSMENT: {dataset_name} ===\")\n",
    "    \n",
    "    # Missing values\n",
    "    missing_pct = (df.isnull().sum() / len(df)) * 100\n",
    "    missing_cols = missing_pct[missing_pct > 0].sort_values(ascending=False)\n",
    "    print(f\"\\nColumns with missing values:\")\n",
    "    for col, pct in missing_cols.items():\n",
    "        print(f\"  {col}: {pct:.2f}%\")\n",
    "    \n",
    "    # Duplicate records\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"\\nDuplicate records: {duplicates} ({duplicates/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    # Data types needing conversion\n",
    "    print(f\"\\nData types:\")\n",
    "    for dtype in df.dtypes.value_counts().items():\n",
    "        print(f\"  {dtype[0]}: {dtype[1]} columns\")\n",
    "    \n",
    "    return missing_cols, duplicates\n",
    "\n",
    "# Assess both datasets\n",
    "thermostat_missing, thermostat_dupes = assess_data_quality(df_thermostat, \"IoT Thermostat\")\n",
    "network_missing, network_dupes = assess_data_quality(df_network, \"Network Traffic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering Strategy\n",
    "\n",
    "Based on the EDA, let's define our feature engineering and preprocessing strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== FEATURE ENGINEERING STRATEGY ===\")\n",
    "print(\"\\n1. IoT Device Features:\")\n",
    "print(\"   - current_temperature: Normalize/scale\")\n",
    "print(\"   - thermostat_status: Binary feature (already encoded)\")\n",
    "print(\"   - date/time: Extract temporal features (hour, day, etc.)\")\n",
    "\n",
    "print(\"\\n2. Network Traffic Features:\")\n",
    "print(\"   - Numerical features: duration, src_bytes, dst_bytes, src_pkts, dst_pkts\")\n",
    "print(\"   - Categorical features: proto, service, conn_state\")\n",
    "print(\"   - IP addresses: Extract network segments or encode\")\n",
    "\n",
    "print(\"\\n3. Class Imbalance Handling:\")\n",
    "print(f\"   - IoT Thermostat: {df_thermostat['label'].value_counts()[0] / df_thermostat['label'].value_counts()[1]:.1f}:1 imbalance\")\n",
    "print(f\"   - Network Traffic: {df_network['label'].value_counts()[1] / df_network['label'].value_counts()[0]:.1f}:1 imbalance\")\n",
    "print(\"   - Use class_weight='balanced' in models\")\n",
    "print(\"   - Consider SMOTE for severe imbalance\")\n",
    "\n",
    "print(\"\\n4. Data Preprocessing Steps:\")\n",
    "print(\"   - Handle missing values (drop or impute)\")\n",
    "print(\"   - Remove duplicates\")\n",
    "print(\"   - Encode categorical variables\")\n",
    "print(\"   - Scale numerical features\")\n",
    "print(\"   - Feature selection based on importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Next Steps\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **IoT Thermostat Dataset**: 442K records, 6 features, 87.3% normal vs 12.7% attacks\n",
    "2. **Network Dataset**: 1M records, 46 features, 79.1% attacks vs 20.9% normal  \n",
    "3. **Class Imbalance**: Both datasets show significant class imbalance requiring handling\n",
    "4. **Data Quality**: Some missing values in date/time fields, minimal duplicates\n",
    "5. **Feature Types**: Mix of numerical, categorical, and temporal features\n",
    "\n",
    "### Next Steps (IOT-R-02 completion):\n",
    "\n",
    "1. **Implement preprocessing pipeline** in `src/preprocess.py`\n",
    "2. **Feature selection** based on correlation and importance\n",
    "3. **Handle class imbalance** with appropriate techniques\n",
    "4. **Create train/test splits** for model development\n",
    "5. **Prepare data** for Random Forest and XGBoost training\n",
    "\n",
    "### Model Strategy:\n",
    "\n",
    "- **Random Forest**: Good baseline, handles mixed data types, built-in feature importance\n",
    "- **XGBoost**: Higher performance target, handles imbalance well, fast training\n",
    "- **Evaluation**: Precision, Recall, F1-Score (critical for imbalanced classes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}